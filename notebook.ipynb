{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad336c92",
   "metadata": {},
   "source": [
    "# ATiCS Sentence Inference Demo\n",
    "\n",
    "This notebook shows how to load a pretrained sentence encoder and evaluate it on custom Natural Language Inference (NLI) examples.  \n",
    "Given a premise and a hypothesis, the model predicts one of three labels: **entailment**, **neutral**, or **contradiction**.\n",
    "\n",
    "Before running the notebook:\n",
    "- Activate the `atics` environment\n",
    "- Download the model checkpoint and `vocab.pkl` from the link in the `README.md`\n",
    "- Make sure the correct GloVe embeddings (e.g. `glove.840B.300d.txt`) are available in the `glove/` directory\n",
    "\n",
    "See the [README.md](./README.md). for setup instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "965dbf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from utils.dataset import tokenizer, build_vocab, load_glove_embeddings\n",
    "from models import get_model\n",
    "import numpy as np\n",
    "\n",
    "# Label mapping\n",
    "ID2LABEL = {0: 'entailment', 1: 'neutral', 2: 'contradiction'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba166ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28250 vectors out of 36704 words.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"checkpoints/vocab.pkl\", \"rb\") as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "glove_path = \"./glove/glove.6B.300d.txt\"\n",
    "embedding_matrix = load_glove_embeddings(glove_path, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b6222d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisa0\\AppData\\Local\\Temp\\ipykernel_22048\\2745710326.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"checkpoints/bilstm_max_best.pt\", map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiLSTMMaxPoolClassifier(\n",
       "  (embedding): Embedding(36704, 300)\n",
       "  (bilstm): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model setup\n",
    "class Args:\n",
    "    hidden_dim = 512\n",
    "    num_classes = 3\n",
    "    max_len = 50\n",
    "    embedding_dim = 300\n",
    "\n",
    "args = Args()\n",
    "model = get_model(\"bilstm_max\", embedding_matrix, args)\n",
    "model.load_state_dict(torch.load(\"checkpoints/bilstm_max_best.pt\", map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ed1b8c",
   "metadata": {},
   "source": [
    "## Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eeffbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(sentence, vocab, max_len=50):\n",
    "    tokens = tokenizer.tokenize(sentence.lower())[:max_len]\n",
    "    ids = [vocab.get(tok, vocab[\"<unk>\"]) for tok in tokens]\n",
    "    ids += [vocab[\"<pad>\"]] * (max_len - len(ids))\n",
    "    return torch.tensor(ids).unsqueeze(0), torch.tensor([min(len(tokens), max_len)])\n",
    "\n",
    "def predict(premise, hypothesis):\n",
    "    x1, len1 = encode_sentence(premise, vocab)\n",
    "    x2, len2 = encode_sentence(hypothesis, vocab)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x1, len1, x2, len2)\n",
    "        probs = F.softmax(logits, dim=1).squeeze()\n",
    "        pred = torch.argmax(probs).item()\n",
    "\n",
    "    print(f\"Premise   : {premise}\")\n",
    "    print(f\"Hypothesis: {hypothesis}\")\n",
    "    print(f\"Prediction: {ID2LABEL[pred]}\")\n",
    "    print(f\"Confidence: {probs[pred]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c85eb7e",
   "metadata": {},
   "source": [
    "## Example Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854f7a17",
   "metadata": {},
   "source": [
    "### Correct Predictions\n",
    "1. The model likely picked up on strong semantic opposition between *having fun* and *fighting*. It may also have learned patterns of contradiction when subjects are similar but actions conflict. Thus it leads to a very high confidence of the contradiction\n",
    "\n",
    "2. The model likely recognizes that *playing a guitar* is a specific instance of *making music*. SNLI contains many paraphrastic examples with *person*/*man* substitutions and verb generalizations, so this pattern is familiar. There's strong lexical and semantic overlap, and no contradiction or neutral information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52bef981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise   : The sisters are having fun\n",
      "Hypothesis: The two girls are fighting\n",
      "Prediction: contradiction\n",
      "Confidence: 0.9999\n",
      "Premise   : A woman is playing a bass.\n",
      "Hypothesis: A person is making music.\n",
      "Prediction: entailment\n",
      "Confidence: 0.9468\n"
     ]
    }
   ],
   "source": [
    "predict(\"The sisters are having fun\", \"The two girls are fighting\") # Ground truth: Contradiction\n",
    "predict(\"A woman is playing a bass.\", \"A person is making music.\")  # Ground truth: Entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ed2b5",
   "metadata": {},
   "source": [
    "### Wrong Predictions\n",
    "\n",
    "1. The model appears overly sensitive to negation (\"nobody\") and treats *sitting in the sun* versus *sitting in the shade* as a contradiction. However, the presence of negation in this context doesnâ€™t necessarily imply a contradiction. Both statements can be true at the same time, so the relationship should be neutral.\n",
    "\n",
    "2. The model is likely misled by the negation (\"no cat\") and interprets it as contradicting the mention of a dog. It may incorrectly treat cat and dog as opposites or mutually exclusive. However, the two sentences are about different subjects, and there's no real semantic conflict. This suggests the model lacks real-world knowledge and struggles with distinguishing unrelated facts from contradictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a80145c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise   : Two men are sitting in the sun.\n",
      "Hypothesis: Nobody is sitting in the shade.\n",
      "Prediction: contradiction\n",
      "Confidence: 0.9747\n",
      "Premise   : A man is walking a dog.\n",
      "Hypothesis: No cat is outside.\n",
      "Prediction: contradiction\n",
      "Confidence: 0.9998\n"
     ]
    }
   ],
   "source": [
    "predict(\"Two men are sitting in the sun.\", \"Nobody is sitting in the shade.\")  # Ground truth: Neutral\n",
    "predict(\"A man is walking a dog.\", \"No cat is outside.\")  # Ground truth: Neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af095b57",
   "metadata": {},
   "source": [
    "## Try Your Own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3e67899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise   : My girlfriend is hungry.\n",
      "Hypothesis: The miss wants to eat.\n",
      "Prediction: neutral\n",
      "Confidence: 0.8370\n"
     ]
    }
   ],
   "source": [
    "# Enter your own sentences here\n",
    "premise = \"My girlfriend is hungry.\"\n",
    "hypothesis = \"The miss wants to eat.\"\n",
    "predict(premise, hypothesis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
